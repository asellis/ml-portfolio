{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6a3763f",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4497f2",
   "metadata": {},
   "source": [
    "This notebook uses a pre-trained language model to perform sentiment analysis on IMDB movie reviews using transfer learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743886c2",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a0ca5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "068b1257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a seed so that results can be reproduced\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)               # PyTorch CPU\n",
    "    torch.cuda.manual_seed(seed)          # PyTorch GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6bc22ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a directory to save/load the model\n",
    "MODEL_DIR = \"./model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cab9afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model name to ensure we have compatible tokenizer and model.\n",
    "MODEL_NAME = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cb1f94",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57d0e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12cae495",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"IMDB\")\n",
    "\n",
    "def tokenize(batch):\n",
    "    # Padding adds a special character to make shorter entries longer.\n",
    "    # Truncation shortens entries which are too long.\n",
    "    # Doing both of these ensures all entries have the same size.\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True)\n",
    "\n",
    "# The encoded dataset is a tokenized version of the dataset which\n",
    "# will be used for training.\n",
    "dataset_encoded = dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052fb497",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8f2b9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2, id2label={0: \"NEGATIVE\", 1: \"POSITIVE\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dedcff",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c5bceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 16\n",
    "epochs = 3\n",
    "learning_rate = 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c5905f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=learning_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97825c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define \"compute_metrics\" function so we can get an accuracy score.\n",
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds)\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_encoded[\"train\"],\n",
    "    eval_dataset=dataset_encoded[\"test\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc16f873",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4689' max='4689' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4689/4689 1:09:17, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.418400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.255400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.224000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.162400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.145700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.138400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.089900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.080800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.081100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4689, training_loss=0.1726846092925394, metrics={'train_runtime': 4158.2047, 'train_samples_per_second': 18.037, 'train_steps_per_second': 1.128, 'total_flos': 1.9733329152e+16, 'train_loss': 0.1726846092925394, 'epoch': 3.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee1263c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1563' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1563/1563 07:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.250809907913208,\n",
       " 'eval_accuracy': 0.94276,\n",
       " 'eval_runtime': 444.4,\n",
       " 'eval_samples_per_second': 56.256,\n",
       " 'eval_steps_per_second': 3.517,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaef6cb",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ad7972",
   "metadata": {},
   "source": [
    "This section is to test a trained model.  It is set up such that we don't have to execute the training steps if we've previously saved a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0af91cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "# Load the model and tokenizer\n",
    "test_tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR, use_fast=True)\n",
    "test_model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86f03a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text-classification\", model=test_model, tokenizer=test_tokenizer, device=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec936920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : I loved this movie!\n",
      "Output: [{'label': 'POSITIVE', 'score': 0.9971131086349487}]\n",
      "\n",
      "Input : This movie was bad!\n",
      "Output: [{'label': 'NEGATIVE', 'score': 0.9984671473503113}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tests = [\n",
    "    \"I loved this movie!\",\n",
    "    \"This movie was bad!\"\n",
    "]\n",
    "\n",
    "for text in tests:\n",
    "    output = pipe(text)\n",
    "    print(f\"Input : {text}\")\n",
    "    print(f\"Output: {output}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f44fc11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
